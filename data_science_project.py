# -*- coding: utf-8 -*-
"""DATA SCIENCE PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yT31s4QjkQSNj9UQCB6tBlE60urhUGeQ

#DEEP LEARNING IN MEDICAL SCIENCE

#AIM  
In this project, i design a nueral network that can be used as a tool to classify medical **chest X-ray images** into clusters of normal and sick people of pneumonia.

#MOTIVATION
The main motivation to build such a nueral network is to have a contribution towards helping a health care system that can be overwhelmed with patients at any instance. This can be used a tool for first assesment of the data obtained before  having trained medical personnel to have a second look.

This tool can also be used in analysing other medical cases from X-ray images which can be hard for normal doctors and for which experienced personnel are scarce.

*It should be noted however, that this tool can not be used as a conclusive one.*


#THE DATA SET
I chose a data set of chest X-ray images of both normal and sick peole of pneumonia because it ican easily be accesible from [kaggle](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).

#ALGORITHMS  IMPLEMENTED
Image classification is a complex task and for this particular problem i decided to use a VGG19 network.

---
**Very Deep Convolutional Networks for Large-Scale Image Recognition by Karen Simonyan, Andrew Zisserman  (2014) **
[(arXiv:1409.1556v6)](https://arxiv.org/abs/1409.1556)

---
MAJOR DRAW BACKS
*   It is painfully slow to train
*   The network architecture weights themselves are quite large

I decided to use the VGG19 network after trials with other networks like;
*   ResNet50
*   Xception
*   InceptionV3
*   InceptionResNetV2	
*   Vgg16

i have designed the programme in a way so that one can experiment and see this by one's self.

#IMPLEMENTATION OF THE NETWORK

#I start by importing all the important libraries I am going to use:

* In case you want to test another model;
 * You must comment all other processors in the next cell (the two lines for each model).
  *You must also change the corresponding model name in line 9 of the second code cell.
"""

import numpy as np
from glob import glob
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd


import tensorflow as tf
from keras.models import load_model
from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential


# THE MODELS

from keras.applications.vgg19 import VGG19 
from keras.applications.vgg19 import preprocess_input

from keras.applications.vgg16 import VGG16
#from keras.applications.vgg16 import preprocess_input 

from keras.applications.inception_resnet_v2 import InceptionResNetV2
#from keras.applications.inception_resnet_v2 import preprocess_input 

from keras.applications.inception_v3 import InceptionV3
#from keras.applications.inception_v3 import preprocess_input

from keras.applications.xception import Xception
#from keras.applications.xception import preprocess_input

from keras.applications.resnet50 import ResNet50
#from keras.applications.resnet50 import preprocess_input

"""#Next I initialise the weights;

By default, the model loads weights pre-trained on [ImageNet.](http://www.image-net.org/about-overview)

The default input size for this model is 224x224.

#[For more information](https://keras.io/api/applications/vgg/#vgg16-function)
"""

# re-size all the images to this
IMAGE_SIZE = [224, 224]                   

#put directories to the training and validation data
train_path = '/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/train'
valid_path = '/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/val'

# add preprocessing layer to the front of VGG
data = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)        

# don't train existing weights   
for layer in data.layers:
  layer.trainable = False
    
# useful for getting number of classes in the given data set
folders = glob('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/train/*')
  
#add more layers if you want
x = Flatten()(data.output)

prediction = Dense(len(folders), activation='softmax')(x)

"""#Visualizing the model
[VGG19](https://miro.medium.com/max/2408/1*6U9FJ_se7SIuFKJRyPMHuA.png)

[VGG16](https://www.researchgate.net/profile/Max_Ferguson/publication/322512435/figure/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png)

[Resnet50](https://eenews.cdnartwhere.eu/sites/default/files/styles/facebook/public/sites/default/files/images/resnet50_630.jpg?itok=fyOGVazd)

[Xception](https://www.deeplearningitalia.com/wp-content/uploads/2018/06/6.png)

[lnception V3](https://alquarizm.files.wordpress.com/2019/03/image-4.png)

[lnception resnet v2](https://www.researchgate.net/profile/Masoud_Mahdianpari/publication/326421398/figure/fig9/AS:649354851385344@1531829669740/Schematic-diagram-of-InceptionResNetV2-model-compressed-view.png)
"""

# create a model object
model = Model(inputs=data.input, outputs=prediction)

# To view the structure of the model, uncomment the line below
#model.summary()

"""#Training the model

Creating more data;

 * consider [this image](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/bird.jpg)

  * Random [Horizontal](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Augmented-Images-with-a-Horizontal-Shift.png) and [Vertical](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Augmented-Images-with-a-Vertical-Shift.png) Shift
  * Random [Horizontal](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Augmented-Images-with-a-Horizontal-Flip.png) and Vertical Flip
  * Random [Rotation](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Images-Generated-with-a-Rotation-Augmentation.png)
  * etc

[adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)

Adam: A Method for Stochastic Optimization
Diederik P. Kingma, Jimmy Ba
[ reference](https://arxiv.org/abs/1412.6980)
"""

# tell the model what cost and optimization method to use
model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)                 #increasing the data set by translations to input

test_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/train',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical') 

test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/val',
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

# fitting the model
r = model.fit_generator(
  training_set,
  validation_data=test_set,
  epochs=5,
  steps_per_epoch=len(training_set),
  validation_steps=len(test_set)
)

"""#Visiualizing the training and validation accuracies and losses"""

# The losses
fig = plt.figure(1)
plt.plot(r.history['loss'], label='training loss')
plt.plot(r.history['val_loss'], label='validation loss')
plt.title('LOSS FUNCTIONS')
plt.ylabel('loss')
plt.xlabel('Number of epochs')
plt.legend()
plt.show()
fig.savefig('LossVal_loss.png')



# The accuracies
fig = plt.figure(2)
plt.plot(r.history['accuracy'], label='training accuracy')
plt.plot(r.history['val_accuracy'], label='validation accuracy')
plt.title('ACCURACY FUNCTIONS')
plt.ylabel('acurracy')
plt.xlabel('Number of epochs')
plt.legend()
plt.show()
fig.savefig('AccVal_acc.png')

"""#Saving the model"""

model.save('model.h5')

"""#Testing the model

First if you want to test just a single picture
"""

model = load_model('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/data science results/vgg19/model_vgg19.h5')

img = image.load_img('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/test/PNEUMONIA/person101_bacteria_483.jpeg', target_size=(224, 224))           #Replace 'path' with the directory of the image you want to test
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
img_data = preprocess_input(x)
classes = model.predict(img_data)

print(classes)

"""Second if you want to test a folder of images"""

#Testing all the folder of normal people

# Load the model you want to use
model = load_model('model.h5')

# Replace the path with the directory of the folder containing normal people data set
path = "/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/test/NORMAL/*"
Nresults=[]
for file in glob(path):
  img = image.load_img(file, target_size=(224, 224))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  img_data = preprocess_input(x)
  classes = model.predict(img_data)
  Nresults=np.append(Nresults,classes[0][0])

# Plotting the results from normal people data set
fig = plt.figure(1)
sns.distplot(Nresults, kde=False,label='normal people data',axlabel='probability distribution') 
plt.legend()
plt.show()
fig.savefig('normal people data.png')

#----------------------------------------------------------------------------------------------------------------------------------------------------------------------

#Testing all the folder of sick people

# Replace the path with the directory of the folder containing sick people data set
path = "/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/test/PNEUMONIA/*"
Nresults=[]
for file in glob(path):
  img = image.load_img(file, target_size=(224, 224))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  img_data = preprocess_input(x)
  classes = model.predict(img_data)
  Nresults=np.append(Nresults,classes[0][0])

# Plotting the results from sick people data set
fig = plt.figure(2)  
sns.distplot(Nresults, kde=False,label='sick people data',axlabel='probability distribution')
plt.legend()
plt.show() 
fig.savefig('sick people data.png')

"""---
#RESULTS
---
**CHECKING WITH SICK PEOPLE DATA**

*They all did a good job at classifying the sick people as sick*
 **(but this was not conclusive)**

**CHECKING WITH NORMAL PEOPLE DATA**

Resnet and Resnetincetion were all very poor here while Vgg16 and inception were not very bad though not good either.

Vgg19 did a fairly good job at classifying normal people as normal with above average results.

#CONCLUSION

The final choice of a VGG19 nueral network is a failry good choice since it does a good job at classifying normal people as normal and very good at classying sick people as sick.

This means most errors will be in classifying normal people as sick and not sick people as normal which makes it a fair tool for implementation besides the fact that its results are not to be considered as conclusive.

#IMPROVEMENTS
One can pontentially improve the results of this project in a number of ways;

* One way is to increase the data set
 
 this can be done by;
  * acquiring more images from hospitals 
  * applying more small functions to the available data (like i did above).

* Try out different [loss functions](https://keras.io/api/losses/)
* Try out adding different layers to the network
* Try different [activation functions](https://keras.io/api/layers/activation_layers/)
* Exploring different weight initaializations
"""