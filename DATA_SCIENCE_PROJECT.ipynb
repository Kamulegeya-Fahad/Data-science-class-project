{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA SCIENCE PROJECT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIdm7w-zwaIL",
        "colab_type": "text"
      },
      "source": [
        "#DEEP LEARNING IN MEDICAL SCIENCE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4bNAEY3p7JM",
        "colab_type": "text"
      },
      "source": [
        "#AIM  \n",
        "In this project, i design a nueral network that can be used as a tool to classify medical **chest X-ray images** into clusters of normal and sick people of pneumonia.\n",
        "\n",
        "#MOTIVATION\n",
        "The main motivation to build such a nueral network is to have a contribution towards helping a health care system that can be overwhelmed with patients at any instance. This can be used a tool for first assesment of the data obtained before  having trained medical personnel to have a second look.\n",
        "\n",
        "This tool can also be used in analysing other medical cases from X-ray images which can be hard for normal doctors and for which experienced personnel are scarce.\n",
        "\n",
        "*It should be noted however, that this tool can not be used as a conclusive one.*\n",
        "\n",
        "\n",
        "#THE DATA SET\n",
        "I chose a data set of chest X-ray images of both normal and sick peole of pneumonia because it ican easily be accesible from [kaggle](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).\n",
        "\n",
        "#ALGORITHMS  IMPLEMENTED\n",
        "Image classification is a complex task and for this particular problem i decided to use a VGG19 network.\n",
        "\n",
        "---\n",
        "**Very Deep Convolutional Networks for Large-Scale Image Recognition by Karen Simonyan, Andrew Zisserman  (2014) **\n",
        "[(arXiv:1409.1556v6)](https://arxiv.org/abs/1409.1556)\n",
        "\n",
        "---\n",
        "MAJOR DRAW BACKS\n",
        "*   It is painfully slow to train\n",
        "*   The network architecture weights themselves are quite large\n",
        "\n",
        "I decided to use the VGG19 network after trials with other networks like;\n",
        "*   ResNet50\n",
        "*   Xception\n",
        "*   InceptionV3\n",
        "*   InceptionResNetV2\t\n",
        "*   Vgg16\n",
        "\n",
        "i have designed the programme in a way so that one can experiment and see this by one's self.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlGwHYiBAMOH",
        "colab_type": "text"
      },
      "source": [
        "#IMPLEMENTATION OF THE NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6wGA2UqxL6N",
        "colab_type": "text"
      },
      "source": [
        "#I start by importing all the important libraries I am going to use:\n",
        "\n",
        "* In case you want to test another model;\n",
        " * You must comment all other processors in the next cell (the two lines for each model).\n",
        "  *You must also change the corresponding model name in line 9 of the second code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32PmzgNK5coR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "f133a583-a07b-46e5-d549-8c07b9c44c90"
      },
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "# THE MODELS\n",
        "\n",
        "from keras.applications.vgg19 import VGG19 \n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from keras.applications.vgg16 import preprocess_input \n",
        "\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "#from keras.applications.inception_resnet_v2 import preprocess_input \n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "from keras.applications.xception import Xception\n",
        "#from keras.applications.xception import preprocess_input\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "#from keras.applications.resnet50 import preprocess_input\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNV99X6nxtPy",
        "colab_type": "text"
      },
      "source": [
        "#Next I initialise the weights;\n",
        "\n",
        "By default, the model loads weights pre-trained on [ImageNet.](http://www.image-net.org/about-overview)\n",
        "\n",
        "The default input size for this model is 224x224.\n",
        "\n",
        "#[For more information](https://keras.io/api/applications/vgg/#vgg16-function)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEeo0-iUxg1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]                   \n",
        "\n",
        "#put directories to the training and validation data\n",
        "train_path = '/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/train'\n",
        "valid_path = '/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/val'\n",
        "\n",
        "# add preprocessing layer to the front of VGG\n",
        "data = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)        \n",
        "\n",
        "# don't train existing weights   \n",
        "for layer in data.layers:\n",
        "  layer.trainable = False\n",
        "    \n",
        "# useful for getting number of classes in the given data set\n",
        "folders = glob('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/train/*')\n",
        "  \n",
        "#add more layers if you want\n",
        "x = Flatten()(data.output)\n",
        "\n",
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acRuvrCG1EwS",
        "colab_type": "text"
      },
      "source": [
        "#Visualizing the model\n",
        "[VGG19](https://miro.medium.com/max/2408/1*6U9FJ_se7SIuFKJRyPMHuA.png)\n",
        "\n",
        "[VGG16](https://www.researchgate.net/profile/Max_Ferguson/publication/322512435/figure/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png)\n",
        "\n",
        "[Resnet50](https://eenews.cdnartwhere.eu/sites/default/files/styles/facebook/public/sites/default/files/images/resnet50_630.jpg?itok=fyOGVazd)\n",
        "\n",
        "[Xception](https://www.deeplearningitalia.com/wp-content/uploads/2018/06/6.png)\n",
        "\n",
        "[lnception V3](https://alquarizm.files.wordpress.com/2019/03/image-4.png)\n",
        "\n",
        "[lnception resnet v2](https://www.researchgate.net/profile/Masoud_Mahdianpari/publication/326421398/figure/fig9/AS:649354851385344@1531829669740/Schematic-diagram-of-InceptionResNetV2-model-compressed-view.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JTkGH1k0_VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a model object\n",
        "model = Model(inputs=data.input, outputs=prediction)\n",
        "\n",
        "# To view the structure of the model, uncomment the line below\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX47Q9cq3fP5",
        "colab_type": "text"
      },
      "source": [
        "#Training the model\n",
        "\n",
        "Creating more data;\n",
        "\n",
        " * consider [this image](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/bird.jpg)\n",
        "\n",
        "  * Random [Horizontal](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Augmented-Images-with-a-Horizontal-Shift.png) and [Vertical](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Augmented-Images-with-a-Vertical-Shift.png) Shift\n",
        "  * Random [Horizontal](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Augmented-Images-with-a-Horizontal-Flip.png) and Vertical Flip\n",
        "  * Random [Rotation](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Plot-of-Images-Generated-with-a-Rotation-Augmentation.png)\n",
        "  * etc\n",
        "\n",
        "[adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
        "\n",
        "Adam: A Method for Stochastic Optimization\n",
        "Diederik P. Kingma, Jimmy Ba\n",
        "[ reference](https://arxiv.org/abs/1412.6980)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLG1_QUx1oRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)                 #increasing the data set by translations to input\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical') \n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/val',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "# fitting the model\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=5,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvy6dx_2esy",
        "colab_type": "text"
      },
      "source": [
        "#Visiualizing the training and validation accuracies and losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGM72FaIcT6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The losses\n",
        "fig = plt.figure(1)\n",
        "plt.plot(r.history['loss'], label='training loss')\n",
        "plt.plot(r.history['val_loss'], label='validation loss')\n",
        "plt.title('LOSS FUNCTIONS')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig.savefig('LossVal_loss.png')\n",
        "\n",
        "\n",
        "\n",
        "# The accuracies\n",
        "fig = plt.figure(2)\n",
        "plt.plot(r.history['accuracy'], label='training accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='validation accuracy')\n",
        "plt.title('ACCURACY FUNCTIONS')\n",
        "plt.ylabel('acurracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig.savefig('AccVal_acc.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OacZ04EP38E3",
        "colab_type": "text"
      },
      "source": [
        "#Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRKBCLjF32c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siADvk7a2R3r",
        "colab_type": "text"
      },
      "source": [
        "#Testing the model\n",
        "\n",
        "First if you want to test just a single picture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjPiEYtgnbnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87e56cf8-45c3-4f3b-9842-6ea82ffd29f5"
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/data science results/vgg19/model_vgg19.h5')\n",
        "\n",
        "img = image.load_img('/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/test/PNEUMONIA/person101_bacteria_483.jpeg', target_size=(224, 224))           #Replace 'path' with the directory of the image you want to test\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "img_data = preprocess_input(x)\n",
        "classes = model.predict(img_data)\n",
        "\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRf1JW41qSai",
        "colab_type": "text"
      },
      "source": [
        "Second if you want to test a folder of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bQtug_IWpiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing all the folder of normal people\n",
        "\n",
        "# Load the model you want to use\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# Replace the path with the directory of the folder containing normal people data set\n",
        "path = \"/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/test/NORMAL/*\"\n",
        "Nresults=[]\n",
        "for file in glob(path):\n",
        "  img = image.load_img(file, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  img_data = preprocess_input(x)\n",
        "  classes = model.predict(img_data)\n",
        "  Nresults=np.append(Nresults,classes[0][0])\n",
        "\n",
        "# Plotting the results from normal people data set\n",
        "fig = plt.figure(1)\n",
        "sns.distplot(Nresults, kde=False,label='normal people data',axlabel='probability distribution') \n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig.savefig('normal people data.png')\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Testing all the folder of sick people\n",
        "\n",
        "# Replace the path with the directory of the folder containing sick people data set\n",
        "path = \"/content/drive/My Drive/Study/INTRODUCTION TO DATA SCIENCE/Other/Deep-Learning-in-Medical-Science-master/chest_xray/test/PNEUMONIA/*\"\n",
        "Nresults=[]\n",
        "for file in glob(path):\n",
        "  img = image.load_img(file, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  img_data = preprocess_input(x)\n",
        "  classes = model.predict(img_data)\n",
        "  Nresults=np.append(Nresults,classes[0][0])\n",
        "\n",
        "# Plotting the results from sick people data set\n",
        "fig = plt.figure(2)  \n",
        "sns.distplot(Nresults, kde=False,label='sick people data',axlabel='probability distribution')\n",
        "plt.legend()\n",
        "plt.show() \n",
        "fig.savefig('sick people data.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTrFzKxteYpp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "#RESULTS\n",
        "---\n",
        "**CHECKING WITH SICK PEOPLE DATA**\n",
        "\n",
        "*They all did a good job at classifying the sick people as sick*\n",
        " **(but this was not conclusive)**\n",
        "\n",
        "**CHECKING WITH NORMAL PEOPLE DATA**\n",
        "\n",
        "Resnet and Resnetincetion were all very poor here while Vgg16 and inception were not very bad though not good either.\n",
        "\n",
        "Vgg19 did a fairly good job at classifying normal people as normal with above average results.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEHeR3wvrA-G",
        "colab_type": "text"
      },
      "source": [
        "#CONCLUSION\n",
        "\n",
        "The final choice of a VGG19 nueral network is a failry good choice since it does a good job at classifying normal people as normal and very good at classying sick people as sick.\n",
        "\n",
        "This means most errors will be in classifying normal people as sick and not sick people as normal which makes it a fair tool for implementation besides the fact that its results are not to be considered as conclusive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0somj5Vs07l",
        "colab_type": "text"
      },
      "source": [
        "#IMPROVEMENTS\n",
        "One can pontentially improve the results of this project in a number of ways;\n",
        "\n",
        "* One way is to increase the data set\n",
        " \n",
        " this can be done by;\n",
        "  * acquiring more images from hospitals \n",
        "  * applying more small functions to the available data (like i did above).\n",
        "\n",
        "* Try out different [loss functions](https://keras.io/api/losses/)\n",
        "* Try out adding different layers to the network\n",
        "* Try different [activation functions](https://keras.io/api/layers/activation_layers/)\n",
        "* Exploring different weight initaializations"
      ]
    }
  ]
}